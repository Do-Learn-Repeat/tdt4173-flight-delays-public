{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Config and Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn pyyaml h5py keras tensorflow numpy xgboost yellowbrick seaborn\n",
    "\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classification labels\n",
    "TARGET_LABELS = ['On Time', 'Behind']\n",
    "\n",
    "# Available locations\n",
    "class Location(Enum):\n",
    "    OSLO = \"OSL\"\n",
    "    TRONDHEIM = \"TRD\"\n",
    "\n",
    "LOCATION = Location.OSLO\n",
    "\n",
    "# Data balance config\n",
    "class SamplingStrategy(Enum):\n",
    "    OVERSAMPLING = 1\n",
    "    UNDERSAMPLING = 2\n",
    "    NONE = 3\n",
    "\n",
    "# Use fixed randomseed, so same datasplits are used for each run?\n",
    "# Only use this when you want a final reproducible result\n",
    "USE_FIXED_RANDOMSEED = True\n",
    "SEED = 64 if USE_FIXED_RANDOMSEED else int(time.time())\n",
    "\n",
    "\n",
    "SVM_MODEL_PATH = \"../models/svm\"          # Models for SVM\n",
    "KNN_MODEL_PATH = \"../models/knn\"          # Models for KNN\n",
    "MLP_MODEL_PATH = \"../models/ann\"          # Models for ANN\n",
    "XGBOOST_MODEL_PATH = \"../models/xgboost\"  # Models for XGBoost\n",
    "\n",
    "SVM_VISUALIZATION_PATH = \"../visualizations/models/svm\"          # Visualizations for SVM\n",
    "KNN_VISUALIZATION_PATH = \"../visualizations/models/knn\"          # Visualizations for KNN\n",
    "MLP_VISUALIZATION_PATH = \"../visualizations/models/ann\"          # Visualizations for ANN\n",
    "XGBOOST_VISUALIZATION_PATH = \"../visualizations/models/xgboost\"  # Visualizations for XGBoost\n",
    "\n",
    "# Set up folder structure\n",
    "for dir in [\n",
    "    SVM_MODEL_PATH, KNN_MODEL_PATH, ANN_MODEL_PATH, XGBOOST_MODEL_PATH, \n",
    "    SVM_VISUALIZATION_PATH, KNN_VISUALIZATION_PATH, ANN_VISUALIZATION_PATH, XGBOOST_VISUALIZATION_PATH\n",
    "]:\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "NUM_FOLDS = 5 # K-value for Cross-Validation\n",
    "SK_LEARNING_CURVE_SPACE = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "source": [
    "## Helper functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def create_pipeline(model, sampling_strategy, _y):\n",
    "    '''\n",
    "    Creates a imblearn datbalancing pipeline, such that databalancing can be combined with CV,\n",
    "    without balancing test-data.\n",
    "    When .fit() method is called on the pipeline, \n",
    "    all training data will go through the chosen sampling_strategy\n",
    "    @model must be a model that implements fit()\n",
    "    '''\n",
    "    if sampling_strategy == SamplingStrategy.NONE:\n",
    "        balancer = 'passthrough'\n",
    "    elif sampling_strategy == SamplingStrategy.UNDERSAMPLING:\n",
    "        databalancing_stats(_y, sampling_strategy)        \n",
    "        balancer = RandomUnderSampler(random_state=SEED)\n",
    "    elif sampling_strategy == SamplingStrategy.OVERSAMPLING:\n",
    "        databalancing_stats(_y, sampling_strategy)\n",
    "        balancer = SMOTE(random_state=SEED, n_jobs=-1)\n",
    "    return make_pipeline(balancer, model)\n",
    "\n",
    "def databalancing_stats(_y, sampling_strategy):\n",
    "    '''\n",
    "    Currently only works for binary problem.\n",
    "    This is only to give user an idea of what will happen to the\n",
    "    training data in the training pipeline, if databalancing is used\n",
    "    '''\n",
    "    original_count = Counter(_y)\n",
    "    print('Following statistics is to get an idea about what will be done to the training-set(s):')\n",
    "    print('Targets before databalancing:', original_count)\n",
    "    if sampling_strategy == SamplingStrategy.OVERSAMPLING:\n",
    "        max_key = max(original_count, key=original_count.get)\n",
    "        new_count = '0: %s 1: %s' % (original_count[max_key], original_count[max_key])\n",
    "    else:\n",
    "        min_key = min(original_count, key=original_count.get)\n",
    "        new_count = '0: %s 1: %s' % (original_count[min_key], original_count[min_key])\n",
    "    print('Targets after databalancing: %s \\n' % new_count)\n",
    "\n",
    "# Synthetic sugar for models wrapped in pipelines\n",
    "def pipeline_search_params(model_name, params):\n",
    "    return {model_name+'__' + key: params[key] for key in params}\n",
    "\n",
    "def create_model_name():\n",
    "  now = datetime.now()\n",
    "  return '%s-%s' % (LOCATION.value, now.strftime(\"%d-%m-%Y-%H%M%S\"))\n",
    "\n",
    "def evaluate_model(X, y, model,  gpu_mode=False):\n",
    "    \"\"\"\n",
    "    Evaulates the model using k-fold kross validation.\n",
    "    ---\n",
    "    returns two dataframes: \n",
    "    1 => scores for all runs\n",
    "    2 => average scores\n",
    "    \"\"\"\n",
    "    cv = StratifiedKFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
    "    N_JOBS = 1 if gpu_mode else -1\n",
    "\n",
    "    scores = cross_validate(model, X, y, scoring=['f1_macro', 'f1_micro'], cv=cv, n_jobs=N_JOBS)\n",
    "\n",
    "    averages = {}\n",
    "    for key, val in scores.items(): \n",
    "        averages[key] = val.mean()\n",
    "\n",
    "    return pd.DataFrame(scores), averages\n",
    "\n",
    "def confusionMatrix(_X, _y, training_pipeline, figPath = None):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(_X, _y, test_size=0.2, random_state=SEED)\n",
    "    model = training_pipeline.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "    data = confusion_matrix(y_test, predicted)\n",
    "\n",
    "    # Below is from https://onestopdataanalysis.com/confusion-matrix-python/\n",
    "    seaborn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(9, 6))\n",
    " \n",
    "    plt.title(\"Confusion Matrix\")\n",
    " \n",
    "    seaborn.set(font_scale=1.4)\n",
    "    ax = seaborn.heatmap(data, annot=True, fmt='g', cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
    " \n",
    "    ax.set_xticklabels((TARGET_LABELS[0], TARGET_LABELS[1]))\n",
    "    ax.set_yticklabels((TARGET_LABELS[0], TARGET_LABELS[1]))\n",
    " \n",
    "    ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
    "    \n",
    "    if not figPath == None:\n",
    "        plt.savefig(figPath+\"/confusion.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_learning_curve(X, y, model, figPath = None):\n",
    "    cv = StratifiedKFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
    "\n",
    "    visualizer = LearningCurve(model, \n",
    "        cv=cv, \n",
    "        scoring='f1_weighted',\n",
    "        train_sizes=SK_LEARNING_CURVE_SPACE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    visualizer.fit(X, y)\n",
    "\n",
    "    if figPath == None:\n",
    "        visualizer.show()\n",
    "    else:\n",
    "        visualizer.show(outpath=figPath+\"/learning.png\")\n",
    "\n",
    "# Plotting Keras learning curve\n",
    "# From: https://stackabuse.com/python-for-nlp-multi-label-text-classification-with-keras/\n",
    "def plot_learning_curve_keras(history):\n",
    "  # Plot accuracy\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train','validation'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot loss\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train','validation'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "# timing can be used to time a code block.\n",
    "# Example:\n",
    "#   with timing():\n",
    "#      expensive_operation()\n",
    "#\n",
    "#   > Finished in _ seconds.\n",
    "class timing:\n",
    "    def __enter__(self):\n",
    "        self.start_time = time.time()\n",
    "    def __exit__(self, type, exc, tb):\n",
    "        print('Finished in {:.3f} seconds'.format(time.time() - self.start_time))"
   ]
  },
  {
   "source": [
    "## Search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridParamSearch(X, y, model, param_dist):\n",
    "    print(\"[GRID SEARCH (CV)] Finding best model using parameters:\")\n",
    "    print(param_dist, end=\"\\n\\n\")\n",
    "\n",
    "    # run grid search\n",
    "    search = GridSearchCV(model, param_grid=param_dist, n_jobs=-1, scoring=\"f1_macro\")\n",
    "    start_time = time.time()\n",
    "    search.fit(X, y)\n",
    "\n",
    "    print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\" % (time.time() - start_time, len(search.cv_results_['params'])))\n",
    "\n",
    "    print(\"\\nBest candidate:\")\n",
    "    print(\"Params\", search.best_params_)\n",
    "    print(\"Score:\", search.best_score_)\n",
    "\n",
    "def randomParamSearch(X, y, model, num_searches, param_dist):\n",
    "    print(\"[RANDOM SEARCH (CV)] Finding best model using parameters:\")\n",
    "    print(param_dist, end=\"\\n\\n\")\n",
    "\n",
    "    # run grid search\n",
    "    search = RandomizedSearchCV(model, param_distributions=param_dist, n_jobs=-1, scoring=\"f1_macro\", n_iter=num_searches)\n",
    "    start_time = time.time()\n",
    "    search.fit(X, y)\n",
    "\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\" % ((time.time() - start_time), num_searches))\n",
    "\n",
    "    print(\"\\nBest candidate:\")\n",
    "    print(\"Params\", search.best_params_)\n",
    "    print(\"Score:\", search.best_score_)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "source": [
    "# Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/clean/%s.csv\" % LOCATION.value)\n",
    "\n",
    "# Select x random-seeded samples from the full dataset\n",
    "df = df.sample(500000, random_state=SEED)\n",
    "df"
   ]
  },
  {
   "source": [
    "## Pre-process data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Feature selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = df[\"TARGET\"]\n",
    "X = df[[\n",
    "    'MONTH',\n",
    "    'DAY_OF_MONTH',\n",
    "    'WEEKDAY',\n",
    "    'HOUR',\n",
    "    'WIND_SPEED', \n",
    "    'WIND_DIRECTION', \n",
    "    'AIR_TEMPERATURE', \n",
    "    'PRECIPITATION', \n",
    "    'VISIBILITY'\n",
    "]]\n",
    "\n",
    "# Parse string features to numeric values\n",
    "le = LabelEncoder()\n",
    "le.fit(df['AIRLINE_IATA'].values)\n",
    "X.insert(2, \"AIRLINE_IATA\", le.transform(df['AIRLINE_IATA'].values), True) \n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['GATE_STAND'].astype(str).values)\n",
    "X.insert(2, \"GATE_STAND\", le.transform(df['GATE_STAND'].astype(str).values), True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['INT_DOM_SCHENGEN'].values)\n",
    "X.insert(2, \"INT_DOM_SCHENGEN\", le.transform(df['INT_DOM_SCHENGEN'].values), True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['DEP_ARR'].values)\n",
    "X.insert(2, \"DEP_ARR\", le.transform(df['DEP_ARR'].values), True) \n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['TO_FROM'].values)\n",
    "X.insert(2, \"TO_FROM\", le.transform(df['TO_FROM'].values), True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['FLIGHT_ID'].values)\n",
    "X.insert(2, \"FLIGHT_ID\", le.transform(df['FLIGHT_ID'].values), True)\n",
    "\n",
    "# print histogram of features\n",
    "X.hist()\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X, y = X.values, y.values"
   ]
  },
  {
   "source": [
    "### Baseline score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import sys\n",
    "sys.path.insert(1, '../src/pipeline')\n",
    "# Our custom weighted dice baseline classifier\n",
    "from baseline import weighted_dice\n",
    "\n",
    "y_test = train_test_split(X, y, test_size=.2, random_state=SEED)[3]\n",
    "\n",
    "targets = Counter(y_test)\n",
    "\n",
    "micros = []\n",
    "macros = []\n",
    "\n",
    "# We average the baseline over 10 runs, to get a more stable score\n",
    "for run in range(10):\n",
    "    y_baseline_pred = [weighted_dice(targets) for target in y_test]\n",
    "    f1_micro = f1_score(y_test, y_baseline_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_baseline_pred, average='macro')\n",
    "    micros.append(f1_micro)\n",
    "    macros.append(f1_macro)\n",
    "\n",
    "micros = np.array(micros)\n",
    "macros = np.array(macros)\n",
    "print('Average scores => f1_macro: %.4f \\tf1_micro: %.4f' % (macros.mean(), micros.mean()))"
   ]
  },
  {
   "source": [
    "# Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# 'Empty' model is declared here and is used on param search,\n",
    "# it's parameters are set in 'Build optmized model' based on\n",
    "# the optimal params found in param search cell\n",
    "svm_pipeline = create_pipeline(SVC(), sampling_strategy=SamplingStrategy.UNDERSAMPLING, _y=y)"
   ]
  },
  {
   "source": [
    "### Param Search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridParamSearch(X, y, svm_pipeline, pipeline_search_params('svc', {\n",
    "#    'C': [1, 2, 5, 10],\n",
    "#    'gamma': [0.01, 0.001, 0.0001],\n",
    "#    'class_weight': ['balanced', None],                          \n",
    "#    'shrinking': [True, False],\n",
    "#}))\n",
    "# 1st search used 50k samples and undersampling.\n",
    "# Best parameters: C=2, class_weight=balanced, gamma=0.0001, shrinking=true => score 0.47\n",
    "\n",
    "# Next => homing in on numerical values. Discard enumerated params (shringing + class_weight).\n",
    "#gridParamSearch(X, y, svm_pipeline, pipeline_search_params('svc', {\n",
    "#    'C': [1.6, 1.85, 2, 2.15, 2.3],\n",
    "#    'gamma': [0.0001, 0.00012, 0.00008],\n",
    "#    'class_weight': ['balanced'],                          \n",
    "#    'shrinking': [True],\n",
    "#}))\n",
    "# 2nd search used 50k samples and undersampling.\n",
    "# Best parameters: C=1.6, class_weight=balanced, gamma=0.00008, shrinking=true => score 0.493\n",
    "\n",
    "# Next => homing in on numerical values. Discard enumerated params (shringing + class_weight).\n",
    "gridParamSearch(X, y, svm_pipeline, pipeline_search_params('svc', {\n",
    "    'C': [1.55, 1.6, 1.65],\n",
    "    'gamma': [0.00007, 0.00008, 0.00009],\n",
    "    'class_weight': ['balanced'],                          \n",
    "    'shrinking': [True],\n",
    "}))\n",
    "# 3rd search used 50k samples and undersampling.\n",
    "# Best parameters: C=1.6, class_weight=balanced, gamma=0.00007, shrinking=true => score 0.494"
   ]
  },
  {
   "source": [
    "### Build Optimal Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params from grid search\n",
    "svm_pipeline = create_pipeline(\n",
    "    SVC(\n",
    "        C=1.6, \n",
    "        class_weight='balanced', \n",
    "        gamma=0.00007, \n",
    "        shrinking=True\n",
    "    ),\n",
    "    sampling_strategy=SamplingStrategy.UNDERSAMPLING, \n",
    "    _y=y\n",
    ")"
   ]
  },
  {
   "source": [
    "### Evaulate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'test_f1_macro': 0.523831637237808, 'test_f1_micro': 0.59231#\n",
    "with timing():\n",
    "    scores, averages = evaluate_model(X, y, svm_pipeline)\n",
    "    print(scores)\n",
    "    print(\"Averages:\", averages)\n",
    "\n",
    "    confusionMatrix(X, y, svm_pipeline, SVM_VISUALIZATION_PATH)"
   ]
  },
  {
   "source": [
    "### Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timing():\n",
    "    plot_learning_curve(X, y, svm_pipeline, SVM_VISUALIZATION_PATH)"
   ]
  },
  {
   "source": [
    "### Save"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = create_model_name()\n",
    "pickle.dump(svm_pipeline, open('%s/%s' % (SVM_MODEL_PATH, model_name), 'wb'))"
   ]
  },
  {
   "source": [
    "## kNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 'Empty' model is declared here and is used on param search,\n",
    "# it's parameters are set in 'Build optmized model' based on\n",
    "# the optimal params found in param search cell\n",
    "knn_pipeline = create_pipeline(KNeighborsClassifier(1), sampling_strategy=SamplingStrategy.UNDERSAMPLING, _y=y)"
   ]
  },
  {
   "source": [
    "### Param Search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#gridParamSearch(X, y, knn_pipeline, pipeline_search_params('kneighborsclassifier', {\n",
    "#    'n_neighbors': [1, 10, 50, 100],\n",
    "#    'weights': ['distance', 'uniform'],\n",
    "#}))\n",
    "# 1st search used 500k samples and undersampling.\n",
    "# Best parameters: K = 10, weights = 'uniform'\n",
    "\n",
    "# Next step: search the area around k=10\n",
    "#gridParamSearch(X, y, knn_pipeline, pipeline_search_params('kneighborsclassifier', {\n",
    "#    'n_neighbors': [6, 8, 10, 12, 14],\n",
    "#    'weights': ['distance', 'uniform'],\n",
    "#}))\n",
    "# 2nd search used 500k samples and undersampling.\n",
    "# Scored 0.5437. Best parameters: K = 6, weights = 'uniform'\n",
    "\n",
    "# Next step: search the area around k=6\n",
    "gridParamSearch(X, y, knn_pipeline, pipeline_search_params('kneighborsclassifier', {\n",
    "    'n_neighbors': [5, 6, 7],\n",
    "    'weights': ['distance', 'uniform'],\n",
    "}))\n",
    "# 3rd search used 500k samples and undersampling.\n",
    "# Scored 0.5437. Best parameters: K = 6, weights = 'uniform'"
   ]
  },
  {
   "source": [
    "### Build Optimal Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params from grid search\n",
    "knn_pipeline = create_pipeline(\n",
    "    KNeighborsClassifier(n_neighbors=6, weights=\"uniform\"), \n",
    "    sampling_strategy=SamplingStrategy.UNDERSAMPLING, _y=y\n",
    ")"
   ]
  },
  {
   "source": [
    "### Evaulate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timing():\n",
    "    scores, averages = evaluate_model(X, y, knn_pipeline)\n",
    "    print(scores)\n",
    "    print(\"Averages:\", averages)\n",
    "\n",
    "    confusionMatrix(X, y, knn_pipeline, KNN_VISUALIZATION_PATH)"
   ]
  },
  {
   "source": [
    "### Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timing():\n",
    "    plot_learning_curve(X, y, knn_pipeline, KNN_VISUALIZATION_PATH)"
   ]
  },
  {
   "source": [
    "### Saving"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = create_model_name()\n",
    "pickle.dump(knn_pipeline, open('%s/%s' % (KNN_MODEL_PATH, model_name), 'wb'))"
   ]
  },
  {
   "source": [
    "## MLP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.regularizers import l2\n",
    "\n",
    "l2_value = 0.00001\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_dim=X.shape[1]))\n",
    "    model.add(Dense(X.shape[1], activation=\"relu\", kernel_initializer='he_uniform', kernel_regularizer=l2(l2_value)))\n",
    "    model.add(Dense(256, activation=\"relu\", kernel_initializer='he_uniform', kernel_regularizer=l2(l2_value)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(256, activation=\"relu\", kernel_initializer='he_uniform', kernel_regularizer=l2(l2_value)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128, activation=\"relu\", kernel_initializer='he_uniform', kernel_regularizer=l2(l2_value)))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "num_epochs = 200\n",
    "batch_size = 4096\n",
    "\n",
    "mlp_model = create_model()\n",
    "print(mlp_model.summary())"
   ]
  },
  {
   "source": [
    "### Evaulate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with timing():\n",
    "    mlp_model_for_evaluation = KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "    mlp_pipeline = create_pipeline(mlp_model_for_evaluation, sampling_strategy=SamplingStrategy.OVERSAMPLING, _y=y)\n",
    "    scores, averages = evaluate_model(X, y, mlp_pipeline, gpu_mode=True)\n",
    "    print('\\n\\n', scores)\n",
    "    print(\"Averages:\", averages)\n",
    "\n",
    "    confusionMatrix(X, y, mlp_pipeline, MLP_VISUALIZATION_PATH)"
   ]
  },
  {
   "source": [
    "### Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_databalancing(_X, _y, sampling_strategy):\n",
    "    if sampling_strategy == SamplingStrategy.UNDERSAMPLING:      \n",
    "        _X, _y = RandomUnderSampler(random_state=SEED).fit_resample(_X, _y)\n",
    "    elif sampling_strategy == SamplingStrategy.OVERSAMPLING:\n",
    "        _X, _y = SMOTE(random_state=SEED, n_jobs=-1).fit_resample(_X, _y)\n",
    "    return _X, _y\n",
    "\n",
    "SPLIT_AND_VALIDATE = True # If False, train with all data\n",
    "SAMPLING_STRATEGY = SamplingStrategy.OVERSAMPLING\n",
    "\n",
    "with timing():\n",
    "    # Custom code for databalancing for MLP, since imblearn pipeline don't return keras-history\n",
    "    if SPLIT_AND_VALIDATE:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=SEED)\n",
    "        if SAMPLING_STRATEGY != SamplingStrategy.NONE:\n",
    "            X_train, y_train = mlp_databalancing(X_train, y_train, SAMPLING_STRATEGY)\n",
    "        history = mlp_model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=0)\n",
    "    else:\n",
    "        X, y = mlp_databalancing(X, y, SAMPLING_STRATEGY)\n",
    "        history = mlp_model.fit(X, y, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    plot_learning_curve_keras(history)"
   ]
  },
  {
   "source": [
    "### Save"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = create_model_name()\n",
    "history.save('%s/%s' % (MLP_MODEL_PATH, model_name))"
   ]
  },
  {
   "source": [
    "## XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 'Empty' model is declared here and is used on param search,\n",
    "# it's parameters are set in 'Build optmized model' based on\n",
    "# the optimal params found in param search cell\n",
    "xgb_pipeline = create_pipeline(XGBClassifier(), sampling_strategy=SamplingStrategy.UNDERSAMPLING, _y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Param Search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridParamSearch(X, y, xgb_pipeline, pipeline_search_params('xgbclassifier', {\n",
    "#    'gamma': [0, 5, 10, 20],\n",
    "#    'learning_rate': [0.1, 0.2, 0.3],                \n",
    "#    'max_depth': [5, 10, 20, 30],\n",
    "#}))\n",
    "# 1st search used 250k samples and undersampling.\n",
    "# Best parameters: gamma=10, learning_rate=0.1, max_depth=30 => score: 0.6114179052808012\n",
    "\n",
    "# Next: Focus parameters\n",
    "gridParamSearch(X, y, xgb_pipeline, pipeline_search_params('xgbclassifier', {\n",
    "    'gamma': [8, 10, 12, 14],\n",
    "    'learning_rate': [0.08, 0.1, 0.12],                \n",
    "    'max_depth': [5, 10, 20, 30],\n",
    "}))\n",
    "# 1st search used 250k samples and undersampling (locking learning rate).\n",
    "# Best parameters: gamma=8, learning_rate=0.08, max_depth=20 => score: 0.6114179052808012"
   ]
  },
  {
   "source": [
    "### Build Optimal Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params from grid search\n",
    "xgb_pipeline = create_pipeline(\n",
    "    XGBClassifier(\n",
    "        gamma=8,\n",
    "        learning_rate=0.08,\n",
    "        max_depth=22,\n",
    "    ), \n",
    "    sampling_strategy=SamplingStrategy.UNDERSAMPLING, \n",
    "    _y=y\n",
    ")\n",
    "# 'test_f1_macro': 0.6275257513386355, 'test_f1_micro': 0.6937688605366897"
   ]
  },
  {
   "source": [
    "### Evaulate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timing():\n",
    "    scores, averages = evaluate_model(X, y, xgb_pipeline)\n",
    "    print(scores)\n",
    "    print(\"Averages:\", averages)\n",
    "\n",
    "    confusionMatrix(X, y, xgb_pipeline, XGBOOST_VISUALIZATION_PATH)"
   ]
  },
  {
   "source": [
    "### Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timing():\n",
    "    plot_learning_curve(X, y, xgb_pipeline, XGBOOST_VISUALIZATION_PATH)"
   ]
  },
  {
   "source": [
    "### Save"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = create_model_name()\n",
    "pickle.dump(xgb_pipeline, open('%s/%s' % (XGBOOST_MODEL_PATH, model_name), 'wb'))"
   ]
  }
 ]
}